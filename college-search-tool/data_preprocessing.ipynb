{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up assets that are needed for data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://github.com/Cledge-org/cledge/blob/dev/features/college_search_tool/assets/\n",
    "\n",
    "https://github.com/Cledge-org/cledge/blob/dev/features/college_search_tool/src/college_search_index_builder.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Update necessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minzhou/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (6,9,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1379,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1412,1413,1427,1428,1431,1432,1503,1517,1532,1533,1534,1535,1536,1537,1538,1539,1540,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1567,1568,1573,1574,1575,1576,1577,1581,1582,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1604,1605,1606,1608,1610,1611,1614,1615,1616,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1636,1638,1640,1643,1644,1648,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1664,1666,1669,1670,1674,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1695,1697,1700,1701,1702,1703,1704,1705,1706,1707,1711,1725,1726,1727,1728,1729,1743,1815,1816,1817,1818,1823,1824,1830,1831,1844,1845,1846,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1909,1910,1911,1912,1913,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1983,1984,2376,2377,2393,2403,2404,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2855,2958) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6694, 2989)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"./data/Most-Recent-Cohorts-All-Data-Elements.csv\")\n",
    "data_dict = pd.read_csv(\"./data/Institution_data_dictionary.csv\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6694, 472)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read previous fields.json file\n",
    "with open(\"./assets/fields.json\") as prevFields:\n",
    "    prevfields_json = json.load(prevFields)\n",
    "\n",
    "# Select columns\n",
    "data_dict_name_map = data_dict[['VARIABLE NAME', 'developer-friendly name']]\n",
    "\n",
    "# re-insert all variable-name & developer-friendly name pairs\n",
    "for variable_name in prevfields_json.keys():\n",
    "    prevfields_json[variable_name] = data_dict_name_map.loc[data_dict_name_map[\"VARIABLE NAME\"] == variable_name, \"developer-friendly name\"].values[0]\n",
    "\n",
    "# write the updated fields into fields.json\n",
    "with open(\"./assets/fields.json\", \"w\") as curFields:\n",
    "    curFields.write(json.dumps(prevfields_json, indent=4))\n",
    "\n",
    "# filter dataset with only fields in the fields.json\n",
    "with open(\"./assets/fields.json\") as curFields:\n",
    "    dataFields = json.load(curFields)\n",
    "    data = data[list(dataFields.keys())]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Update and Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read previous datatypes.json file\n",
    "with open(\"./assets/datatypes.json\") as prevDTypes:\n",
    "    prevDTypes_json = json.load(prevDTypes)\n",
    "\n",
    "# Select API data type and VARIABLE NAME from data_dict\n",
    "data_dict_data_type = data_dict[['VARIABLE NAME', 'API data type']]\n",
    "\n",
    "for dtype_name in prevDTypes_json.keys():\n",
    "    prevDTypes_json[dtype_name] = data_dict_data_type.loc[data_dict_data_type['VARIABLE NAME'] == dtype_name, \"API data type\"].values[0]\n",
    "\n",
    "# write the updated fields into datatypes.json\n",
    "with open(\"./assets/datatypes.json\", \"w\") as curDTypes:\n",
    "    curDTypes.write(json.dumps(prevDTypes_json, indent=4))\n",
    "\n",
    "# manually edit \"autocomplete\" data type into \"string\" (\"INSTNM\" and \"CITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save current data into csv\n",
    "data.to_csv(\"./data/Necessary-Fields-Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset using PySpark\n",
    "df = spark.read.csv(\"./data/Necessary-Fields-Data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PySpark to check and convert data types\n",
    "with open('./assets/datatypes.json') as f:\n",
    "    datatypes = json.load(f)\n",
    "\n",
    "# cast columns to correct datatypes\n",
    "for field, datatype in datatypes.items(): # takes a few mins to run\n",
    "    if field not in df.columns:\n",
    "        continue\n",
    "    curr_type = dict(df.dtypes)[field]\n",
    "    if curr_type != datatype and not datatype.startswith(curr_type):\n",
    "        df = df.withColumn(field, F.col(field).cast(datatype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Empty (Null) Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all \"NULL\" values in dataframe with literal null values so that isnull() can be used\n",
    "df = df.replace({'NULL': None, 'null': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    }
   ],
   "source": [
    "# Drop fields that are completely null\n",
    "num_rows = df.count()\n",
    "\n",
    "for field, null_count in null_counts.items():\n",
    "    if null_count >= num_rows: # all values of field are null, drop the field\n",
    "        df = df.drop(field)\n",
    "print(len(df.columns)) # number of fields that are not completely null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary of null value counts for reference\n",
    "with open('./assets/null_counts.json', 'w') as f:\n",
    "    json.dump(null_counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----+\n",
      "|INSTNM                           |HBCU|\n",
      "+---------------------------------+----+\n",
      "|Howard University                |1.0 |\n",
      "|Howard Community College         |0.0 |\n",
      "|Specs Howard School of Media Arts|0.0 |\n",
      "|Howard College                   |0.0 |\n",
      "|Howard Payne University          |0.0 |\n",
      "+---------------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test that casting worked: Howard University should be true for HBCU\n",
    "df.where(df.INSTNM.contains('Howard')).select([\"INSTNM\", \"HBCU\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-------+\n",
      "|INSTNM                                 |CCBASIC|\n",
      "+---------------------------------------+-------+\n",
      "|University of Washington-Seattle Campus|15.0   |\n",
      "|University of Washington-Bothell Campus|18.0   |\n",
      "|University of Washington-Tacoma Campus |18.0   |\n",
      "+---------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace \"CCBASIC\" with any field name (or add other field names to the select list) from fields.json to print out specific fields for UW campuses\n",
    "df.where(df.INSTNM.contains('University of Washington')).select([\"INSTNM\", \"CCBASIC\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "df_filename = './data/college-search-data.parquet'\n",
    "df.write.save(df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./assets/datatypes.json\") as curDTypes:\n",
    "#     cur_dataTypes = json.load(curDTypes)\n",
    "\n",
    "# for column in data.columns:\n",
    "#     col_dataType = str(data[column].dtypes)\n",
    "#     expect_dataType = cur_dataTypes[column]\n",
    "#     is_equal = False\n",
    "#     if expect_dataType == \"integer\":\n",
    "#         if not col_dataType == \"int64\":\n",
    "#             data[column].astype(\"int\", errors='ignore')\n",
    "#     elif expect_dataType == \"float\":\n",
    "#         if not col_dataType == \"float64\":\n",
    "#             data[column].astype(\"float\", errors='ignore')\n",
    "#     else:\n",
    "#         if not col_dataType == \"object\":\n",
    "#             data[column].astype(\"string\", errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in data.columns:\n",
    "#     col_dataType = str(data[column].dtypes)\n",
    "#     expect_dataType = cur_dataTypes[column]\n",
    "#     is_equal = False\n",
    "#     if expect_dataType == \"integer\":\n",
    "#         if col_dataType == \"int64\":\n",
    "#             is_equal = True\n",
    "#     elif expect_dataType == \"float\":\n",
    "#         if col_dataType == \"float64\":\n",
    "#             is_equal = True\n",
    "#     else:\n",
    "#         if col_dataType == \"string\" or col_dataType == \"object\":\n",
    "#             is_equal = True\n",
    "#     if not is_equal:\n",
    "#         print(column)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a17e3a3172cf46aaf637e4c7681713daf53374be115d411b165dfc3d728fe3c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
