{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ic2020mission.csv column name into uppercase\n",
    "ic2020mission_df = pd.read_csv(\"./data/v2_additional_data/IC2020Mission.csv\")\n",
    "ic2020mission_df = ic2020mission_df.rename(columns={\"unitid\":\"UNITID\", \"missionURL\": \"MISSIONURL\", \"mission\": \"MISSION\"})\n",
    "ic2020mission_df.to_csv(\"./data/v2_additional_data/IC2020Mission_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_filename = './data/college-search-data.parquet'\n",
    "df = spark.read.load(df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6694, 446)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatypes_route = \"./assets/datatypes.json\"\n",
    "v2_additional_route = \"./data/v2_additional_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes for each additional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 columns\n",
    "hd2020_columns = {\n",
    "    \"ADDR\": \"string\",\n",
    "    \"GENTELE\": \"string\",\n",
    "    \"INSTCAT\": \"integer\",\n",
    "    \"LANDGRNT\": \"integer\",\n",
    "    \"C18IPUG\": \"integer\",\n",
    "    \"C18UGPRF\": \"integer\",\n",
    "    \"C18ENPRF\": \"integer\",\n",
    "    \"C18SZSET\": \"integer\",\n",
    "    \"IALIAS\": \"string\",\n",
    "    \"INSTSIZE\": \"integer\"\n",
    "}\n",
    "\n",
    "# 12 columns\n",
    "ic2020_columns = {\n",
    "    # \"RELAFFIL\": \"integer\",\n",
    "    # \"OPENADMP\": \"integer\",\n",
    "    \"SLO5\": \"integer\",\n",
    "    \"ASSOC1\": \"integer\",\n",
    "    \"SPORT1\": \"integer\",\n",
    "    \"SPORT2\": \"integer\",\n",
    "    \"SPORT3\": \"integer\",\n",
    "    \"SPORT4\": \"integer\",\n",
    "    \"CALSYS\": \"integer\",\n",
    "    \"APPLFEEU\": \"integer\",\n",
    "    \"FT_UG\": \"integer\",\n",
    "    \"RMBRDAMT\": \"integer\"\n",
    "}\n",
    "\n",
    "# 11 columns\n",
    "adm2020_columns = {\n",
    "    \"ADMCON1\": \"integer\",\n",
    "    \"ADMCON2\": \"integer\",\n",
    "    \"ADMCON3\": \"integer\",\n",
    "    \"ADMCON4\": \"integer\",\n",
    "    \"ADMCON5\": \"integer\",\n",
    "    \"ADMCON6\": \"integer\",\n",
    "    \"ADMCON7\": \"integer\",\n",
    "    \"SATPCT\": \"integer\",\n",
    "    \"ACTPCT\": \"integer\",\n",
    "    \"ENRLM\": \"integer\",\n",
    "    \"ENRLW\": \"integer\"\n",
    "}\n",
    "\n",
    "# 5 columns\n",
    "drvadm2020_columns = {\n",
    "    \"DVADM02\": \"integer\",\n",
    "    \"DVADM03\": \"integer\",\n",
    "    \"DVADM08\": \"integer\",\n",
    "    \"DVADM09\": \"integer\",\n",
    "    \"DVADM04\": \"integer\"\n",
    "}\n",
    "\n",
    "# 1 column\n",
    "ic2020mission_columns = {\n",
    "    \"MISSION\": \"string\"\n",
    "}\n",
    "\n",
    "# 4 columns\n",
    "drvic2020_columns = {\n",
    "    \"CINSON\": \"integer\",\n",
    "    \"COTSON\": \"integer\",\n",
    "    \"CINSOFF\": \"integer\",\n",
    "    \"COTSOFF\": \"integer\"\n",
    "}\n",
    "\n",
    "# 2 columns\n",
    "ic2020_ay_columns = {\n",
    "    \"TUITION2\": \"integer\",\n",
    "    \"TUITION3\": \"integer\"\n",
    "}\n",
    "\n",
    "# 1 column\n",
    "# ef2020a_columns = {\n",
    "#     \"EFNRALT\": \"integer\"\n",
    "# }\n",
    "\n",
    "# 2 columns\n",
    "ef2020b_columns = {\n",
    "    \"EFAGE07\": \"integer\",\n",
    "    \"EFAGE08\": \"integer\"\n",
    "}\n",
    "\n",
    "# 3 columns\n",
    "# didn't include percent enrolled ethnicity, currently included\n",
    "drvef2020_columns = {\n",
    "    \"ENRTOT\": \"integer\",\n",
    "    \"EFUG\": \"integer\",\n",
    "    \"EFGRAD\": \"integer\"\n",
    "}\n",
    "\n",
    "# 1 column\n",
    "ef2020d_columns = {\n",
    "    \"STUFACR\": \"integer\"\n",
    "}\n",
    "\n",
    "# 52 columns overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_new_data(datatype_dict, dataset_name, df):\n",
    "    colNames = list(datatype_dict.keys())\n",
    "    with open(datatypes_route) as f:\n",
    "        cur_datatypes = json.load(f)\n",
    "\n",
    "    # print(len(cur_datatypes))\n",
    "\n",
    "    for colName in colNames:\n",
    "        cur_datatypes[colName] = datatype_dict[colName]\n",
    "\n",
    "    # print(len(cur_datatypes))\n",
    "\n",
    "    with open(datatypes_route, 'w') as f:\n",
    "        f.write(json.dumps(cur_datatypes, indent=4))\n",
    "    \n",
    "    colNames.append(\"UNITID\")\n",
    "\n",
    "    v2df = spark.read.csv(v2_additional_route + dataset_name, header=True, inferSchema=True)\n",
    "    v2df = v2df.withColumn(\"UNITID\", F.col(\"UNITID\").cast(\"string\"))\n",
    "    v2df = v2df.select(colNames)\n",
    "    \n",
    "    df = df.join(v2df, \"UNITID\", \"left\")\n",
    "    print((df.count(), len(df.columns)))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6694, 456)\n",
      "(6694, 466)\n",
      "(6694, 477)\n",
      "(6694, 482)\n",
      "(6694, 483)\n",
      "(6694, 487)\n",
      "(6694, 489)\n"
     ]
    }
   ],
   "source": [
    "df = concatenate_new_data(hd2020_columns, \"HD2020.csv\", df)\n",
    "df = concatenate_new_data(ic2020_columns, \"IC2020.csv\", df)\n",
    "df = concatenate_new_data(adm2020_columns, \"ADM2020.csv\", df)\n",
    "df = concatenate_new_data(drvadm2020_columns, \"DRVADM2020.csv\", df)\n",
    "df = concatenate_new_data(ic2020mission_columns, \"IC2020Mission_updated.csv\", df)\n",
    "df = concatenate_new_data(drvic2020_columns, \"DRVIC2020.csv\", df)\n",
    "df = concatenate_new_data(ic2020_ay_columns, \"IC2020_AY.csv\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6694"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"UNITID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81498, 491)\n"
     ]
    }
   ],
   "source": [
    "df = concatenate_new_data(ef2020b_columns, \"EF2020B.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58277"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"EFAGE07\", \"EFAGE08\", \"UNITID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = concatenate_new_data(ef2020a_columns, \"EF2020A.csv\", df)\n",
    "df = concatenate_new_data(ef2020b_columns, \"EF2020B.csv\", df)\n",
    "df = concatenate_new_data(drvef2020_columns, \"DRVEF2020.csv\", df)\n",
    "df = concatenate_new_data(ef2020d_columns, \"EF2020D.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# hd2020_colName = list(hd2020_columns.keys())\n",
    "# hd2020_colName.append(\"UNITID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datatypes_route) as f:\n",
    "    cur_datatypes = json.load(f)\n",
    "\n",
    "for colName in hd2020_colName:\n",
    "    cur_datatypes[colName] = hd2020_columns[colName]\n",
    "\n",
    "with open(datatypes_route, 'w') as f:\n",
    "    f.write(json.dumps(cur_datatypes, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd2020 = spark.read.csv(\"./data/v2_additional_data/HD2020.csv\", header=True, inferSchema=True)\n",
    "hd2020 = hd2020.withColumn(\"UNITID\", F.col(\"UNITID\").cast(\"string\"))\n",
    "hd2020 = hd2020.select(hd2020_colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(hd2020, \"UNITID\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6694, 456)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'NULL': None, 'null': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a17e3a3172cf46aaf637e4c7681713daf53374be115d411b165dfc3d728fe3c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
